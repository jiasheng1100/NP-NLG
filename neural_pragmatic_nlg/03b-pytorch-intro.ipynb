{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFJGH3e_ilgc"
      },
      "source": [
        "Sheet 2.1: PyTorch essentials\n",
        "=============================\n",
        "\n",
        "**Author:** Michael Franke\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm_pRv-lilgf"
      },
      "source": [
        "This work sheet introduces the very basics of PyTorch.\n",
        "If you want to install PyTorch locally on your machine, follow [these instructions](https://pytorch.org/get-started/locally/).\n",
        "If installed, import the library to make it usable:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jCU8H2_Filgg"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtn6WOLxilgh"
      },
      "source": [
        "## Tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkgx5ZDDilgi"
      },
      "source": [
        "Tensors are the default data structure used for the representation of\n",
        "numbers in PyTorch. In mathematics (algebra), a tensor is a\n",
        "generalization of the concept of a matrix. For our purposes, let&rsquo;s think\n",
        "of a tensor as basically an $n$-dimensional array of numbers.\n",
        "\n",
        "For example, a single scalar (a single number) is a zero-dimensional\n",
        "array. An $n$-dimensional vector is a one-dimensional array of $n$\n",
        "numbers. An $n \\times m$ matrix is a two-dimensional array with $n$\n",
        "rows and $m$ columns. All of these -scalars, vectors and matrices- are\n",
        "tensors. But *tensors also include even more high-dimensional objects*.\n",
        "For instance, an $k \\times n \\times m$ tensor is a three-dimensional\n",
        "array, which includes $k$ matrices, each of which has $n$ rows and\n",
        "$m$ columns. And so on.\n",
        "\n",
        "Full documetation for the \\`torch.Tensor\\` class can be found here:\n",
        "[https://pytorch.org/docs/stable/tensors.html](https://pytorch.org/docs/stable/tensors.html)\n",
        "\n",
        "![img](https://github.com/michael-franke/npNLG/blob/main/neural_pragmatic_nlg/pics/03-scalars-vectors-matrices-tensors.png?raw=1)\n",
        "\n",
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.1: Dimensions of tensors</span></strong>\n",
        ">\n",
        "> What are the dimensions of the following tensors?\n",
        ">\n",
        "> 1. $1$\n",
        "> 2. $[1,2,3]$\n",
        "> 3. $[[1,2], [3,4]]$\n",
        "> 4. $[[1,2], [3,4], [5,6]]$\n",
        "> 5. $[[[1,2], [3,4], [5,6]]]$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answers to Exercise 2.1.1:\n",
        "1. 0\n",
        "2. 1\n",
        "3. 2\n",
        "4. 2\n",
        "5. 3"
      ],
      "metadata": {
        "id": "V0hhlLUakLkq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wurmw8Tlilgj"
      },
      "source": [
        "## Creating a tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIM3PzHtilgk"
      },
      "source": [
        "There are various ways to create a tensor in PyTorch.\n",
        "We will go through a few examples here.\n",
        "\n",
        "Tensors can be initialised from a list:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JbaB5bRyilgl",
        "outputId": "e1b0cd2f-c115-4184-c86d-7aef051bdc42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "a_list = [1, 2, 3, 4]\n",
        "tensor_from_list = torch.tensor(a_list)\n",
        "tensor_from_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTpZXQOAilgm"
      },
      "source": [
        "Or directly:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lpl45Ozjilgn",
        "outputId": "223fdb09-49c9-424c-b80a-f0c4229953d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "new_tensor = torch.tensor([1, 2, 3, 4])\n",
        "new_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-6hbZ8Filgo"
      },
      "source": [
        "Tensor construction will replicate shape and dimensionality of the data\n",
        "passed to it:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gZMbdTD1ilgp",
        "outputId": "3ad28760-9df2-4851-d7ca-29c1c0bdb42a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tensor_0d = torch.tensor(1)\n",
        "tensor_0d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pkGrBB9nilgq",
        "outputId": "9c37cc55-c5f2-412d-8705-ad445bdf83be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tensor_2d = torch.tensor([[1,2,3],[4,5,6]])\n",
        "tensor_2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbXmXnDrilgq"
      },
      "source": [
        "Tensors can also be constructed from numpy arrays:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7nyCLt-gilgr",
        "outputId": "41fafa3c-e133-46a1-a4a0-ecf6f0bc22ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.zeros((2,2))\n",
        "np_array_to_tensor = torch.tensor(np_array)\n",
        "np_array_to_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcMz8Kmrilgs"
      },
      "source": [
        "Or with build-in torch functionality:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F0MCGoVHilgs",
        "outputId": "ac1205b7-ab21-4cec-cdbd-d1a3694b4161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "zeros = torch.zeros((2,2))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ASd1vrbKilgt",
        "outputId": "62c7c1f3-042d-4ca1-d339-01c4e8a170be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ones = torch.ones((2,3))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DoU4gInkilgu",
        "outputId": "52086f91-e02d-4496-f722-5c723dd64163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 5, 5],\n",
              "        [5, 5, 5],\n",
              "        [5, 5, 5],\n",
              "        [5, 5, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "filled = torch.full((4,3), 5)\n",
        "filled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmHUnacnilgu"
      },
      "source": [
        "Often we might also want to fill tensors with random numbers.\n",
        "The function \\`torch.rand()\\` populates a tensor of the given size with random numbers drawn uniformly from the unit interval.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5WM0gCgAilgv",
        "outputId": "991bf4ba-4335-4a06-df37-a3793e53ee76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1777, 0.4250, 0.7577],\n",
              "        [0.2019, 0.5146, 0.4679]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "torch.rand((2,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnXpG-mMilgv"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.2: Creating tensors</span></strong>\n",
        ">\n",
        "> 1. Create a PyTorch tensor storing the following matrices:\n",
        ">\n",
        ">   a. $[[1,2], [3,4], [5,6]]$\n",
        ">\n",
        ">   b. $[[[1,2], [3,4], [5,6]], [[10,20], [30,40], [50,60]]]$\n",
        ">\n",
        "> 2. Create a PyTorch tensor of size $3 \\times 2 \\times 4$ filled with the number 3.\n",
        ">\n",
        ">\n",
        ">\n",
        "> 3. Create a PyTorch vector with 6 random numbers (lying between 0 and 1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1a\n",
        "tensor1a = torch.tensor([[1,2],[3,4],[5,6]])\n",
        "tensor1a"
      ],
      "metadata": {
        "id": "OoOShN1FloE6",
        "outputId": "eb2e2593-6e3f-4a25-b35b-c7d3bd2b9003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1b\n",
        "tensor1b = torch.tensor([[[1,2],[3,4],[5,6]],[[10,20],[30,40],[50,60]]])\n",
        "tensor1b"
      ],
      "metadata": {
        "id": "FRFfWwKOl6FD",
        "outputId": "8decbcf0-b1a5-45b4-8c08-0158b913b497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2],\n",
              "         [ 3,  4],\n",
              "         [ 5,  6]],\n",
              "\n",
              "        [[10, 20],\n",
              "         [30, 40],\n",
              "         [50, 60]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2\n",
        "tensor2 = torch.full((3, 2, 4), 3)\n",
        "tensor2"
      ],
      "metadata": {
        "id": "m07TrF_vmKOl",
        "outputId": "361a1e12-1015-40ec-f6eb-f3da5d722378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[3, 3, 3, 3],\n",
              "         [3, 3, 3, 3]],\n",
              "\n",
              "        [[3, 3, 3, 3],\n",
              "         [3, 3, 3, 3]],\n",
              "\n",
              "        [[3, 3, 3, 3],\n",
              "         [3, 3, 3, 3]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3\n",
        "tensor3 = torch.rand(6)\n",
        "tensor3"
      ],
      "metadata": {
        "id": "RBUGFTbsmf-c",
        "outputId": "e890b395-e37d-4a2b-e780-c704ce17b04e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7459, 0.7543, 0.1678, 0.9200, 0.0344, 0.8020])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiYHQ1zHilgw"
      },
      "source": [
        "## Row & column vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fggfxubcilgw"
      },
      "source": [
        "A one-dimensional tensor is a row-vector:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5JtJkjvpilgx",
        "outputId": "82828b9d-bb3c-479c-a880-eab984015604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  1,  10, 100])\n",
            "torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "row_vector = torch.tensor([1,10,100])\n",
        "print(row_vector)\n",
        "print(row_vector.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRAtCd08ilgy"
      },
      "source": [
        "Strictly speaking, there are no column vectors in PyTorch.\n",
        "A column vector would be a matrix with one column:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8yu2MxDOilgy",
        "outputId": "d70a06f0-572e-4237-8211-13b7562febfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1],\n",
            "        [ 10],\n",
            "        [100]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "col_vector = torch.tensor([[1],[10],[100]])\n",
        "print(col_vector)\n",
        "print(col_vector.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVQUKuvjilgz"
      },
      "source": [
        "## Tensor data types\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXWCFzP8ilgz"
      },
      "source": [
        "Tensor-supported data types are:\n",
        "\n",
        "-   numeric: float, int\n",
        "-   boolean\n",
        "-   complex numbers\n",
        "\n",
        "We can retrieve the type of a tensor with \\`.dtype\\`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LbigkOA5ilgz",
        "outputId": "b8e427b3-d207-43cc-c371-16fe5506e522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "torch.tensor([1.5, 2.1]).dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om2opT8milg0"
      },
      "source": [
        "If we construct a tensor with an integer, its type will be integer.\n",
        "Compare:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gUVs_I2kilg0",
        "outputId": "b21e1636-41c5-4dd3-c0f4-3ca847dd7f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(torch.tensor(5).dtype)\n",
        "print(torch.tensor(5.0).dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYVQUapdilg0"
      },
      "source": [
        "It is possible to declare the type explicitly, when constructing a tensor:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VhSuOuHoilg1",
        "outputId": "c96ef3b1-56b6-402b-c3ae-517684b08ac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.bool\n"
          ]
        }
      ],
      "source": [
        "print(torch.tensor(5,   dtype=torch.float64).dtype)\n",
        "print(torch.tensor(1.0, dtype=torch.bool).dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E7O4ffzilg1"
      },
      "source": [
        "All the values in the same tensor are of the same data type.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vCx21-Huilg2",
        "outputId": "ca671e25-850a-4160-a377-8119e54eab99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True])\n",
            "torch.bool\n"
          ]
        }
      ],
      "source": [
        "true = torch.tensor([True, True])\n",
        "print(true)\n",
        "print(true.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz9gv6PZilg2"
      },
      "source": [
        "Careful: PyTorch will implicitly cast data types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1lGTBxCCilg2",
        "outputId": "1ea533e5-6b55-47b7-b6ec-89c128a19341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1])\n",
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "mix = torch.tensor([True, 1])\n",
        "print(mix)\n",
        "print(mix.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJcni2quilg2"
      },
      "source": [
        "What about strings? PyTorch tensors have no character or string data\n",
        "type support.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kxAUETY_ilg2",
        "outputId": "21882cfb-f514-49c0-9032-aba87c4ebc9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 72, 101, 108, 108, 111,  32,  87, 111, 114, 108, 100,  33])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "hello        = 'Hello World!'\n",
        "hello_tensor = torch.tensor([ord(char) for char in hello])\n",
        "hello_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8oi78Nilg3"
      },
      "source": [
        "## Attributes of a tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZercjnB0ilg3"
      },
      "source": [
        "Tensors have attributes, which store information about some of their important properties.\n",
        "Here are some important examples:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CfyzZDDEilg3",
        "outputId": "6fe8331d-0fd6-4cec-ff76-d1c327241c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of tensor         : torch.int64\n",
            "Shape of tensor            : torch.Size([12])\n",
            "Device tensor is stored on : cpu\n"
          ]
        }
      ],
      "source": [
        "print(f\"Datatype of tensor         : {hello_tensor.dtype}\")\n",
        "print(f\"Shape of tensor            : {hello_tensor.shape}\")\n",
        "print(f\"Device tensor is stored on : {hello_tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4xnrtCWilg4"
      },
      "source": [
        "We have seen \\`dtype\\` already.\n",
        "The property \\`shape\\` gives equal output as a call to function \\`.size()\\`.\n",
        "The property assessed with \\`.device\\` tells us where the tensor is stored and manipulated.\n",
        "The default is the CPU.\n",
        "If your machine allows you can also shift all your tensors to a GPU.\n",
        "The syntax for doing this is slightly different on different machines.\n",
        "\n",
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.3: Tensor attributes & types </span></strong>\n",
        ">\n",
        "> 1. Inspect the tensor type with \\`.dtype\\` for tensors created from a list containing two different data types supported by PyTorch (int, float, Boolean).\n",
        ">\n",
        "> 2. Use \\`.shape\\` or \\`.size()\\` to inspect the shape of a (row) vector, a single column matrix, and a $2 \\times 3$ matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2.1.3.1\n",
        "type1 = torch.tensor([1, 1.7, 1, 1, 1.3])\n",
        "type1.dtype"
      ],
      "metadata": {
        "id": "COFZqZP_wfuB",
        "outputId": "aa9ab80c-af1a-47ac-ccae-0882c0f53c0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2.1.3.2\n",
        "row_vector = torch.tensor([1, 2, 3, 4, 5])\n",
        "col_vector = torch.tensor([[1], [2], [3], [4], [5]])\n",
        "matrix = torch.zeros((2, 3))\n",
        "print(row_vector.shape)\n",
        "print(col_vector.shape)\n",
        "print(matrix.shape)"
      ],
      "metadata": {
        "id": "yuYDaWAjxFin",
        "outputId": "bab63e07-0909-4ade-f9fa-94abb6330a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5])\n",
            "torch.Size([5, 1])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAT4ywyuilg4"
      },
      "source": [
        "## Operations on tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h0QBqO2ilg5"
      },
      "source": [
        "### Indexing and slicing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmFzgYduilg5"
      },
      "source": [
        "Indexing & slicing works in the way familiar from numpy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "edzR_p6dilg6",
        "outputId": "5f3e1ea5-7a2b-4e68-924f-98fea79ab439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor(6)\n",
            "tensor([7, 8, 9])\n",
            "tensor([7, 8, 9])\n",
            "tensor([2, 5, 8])\n"
          ]
        }
      ],
      "source": [
        "matrix = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
        "print(matrix)\n",
        "print(matrix[1,2])   # single element\n",
        "print(matrix[2,:])   # third row\n",
        "print(matrix[2])     # third row (alternative)\n",
        "print(matrix[:,1])   # second column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sgzvW2_ilg6"
      },
      "source": [
        "### Joining tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PlyM-Hsilg7"
      },
      "source": [
        "We can concatenate tensor like so:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Os4PHGWHilg7",
        "outputId": "008d4461-b894-4886-881e-9a38e5492e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n"
          ]
        }
      ],
      "source": [
        "head          = torch.tensor([1,2,3])\n",
        "tail          = torch.tensor([4,5,6])\n",
        "head_and_tail = torch.cat([head, tail])\n",
        "print(head_and_tail)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdZjpoCFilg8"
      },
      "source": [
        "What if we want to add a dimension?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Al43Jooyilg8",
        "outputId": "6b8d1330-dd42-4a56-9260-2967a42fef89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.stack([head, tail]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyHUywhVilg8"
      },
      "source": [
        "### Reshaping\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXf0sztqilg9"
      },
      "source": [
        "The function \\`torch.reshape()\\` is a frequently used way of returning a tensor in the\n",
        "specified shape.\n",
        "Its input are the desired output dimensions.\n",
        "NB: the reshaping returns a new tensor and does not modify the old tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gWuOIOXNilg9",
        "outputId": "4efcfee5-7f38-44d6-ff23-255edbc15e3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ],
      "source": [
        "tensor_1 = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor_2 = tensor_1.reshape(4, 1)\n",
        "print(tensor_1)\n",
        "print(tensor_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RVdTqB_4ilg-",
        "outputId": "70942201-fbdf-4b1c-83ab-d0729588afa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3]])\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [3]])\n",
            "tensor([[0, 1, 2, 3]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[0, 1],\n",
        "                  [2, 3]])\n",
        "b = torch.reshape(a, (-1,))      # to (row) vector\n",
        "c = torch.reshape(a, (-1, 1))    # to one col matrix (~ col vector)\n",
        "d = torch.reshape(a, (1, -1))    # to one row matrix\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEYpCjQwilg-"
      },
      "source": [
        "There is also the function \\`.flatten()\\` which returns all elements of a tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HOBb80ljilg-",
        "outputId": "2a70cec9-7cac-4a1b-a59f-7a29d2d5b14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0, 1],\n",
            "         [2, 3]],\n",
            "\n",
            "        [[4, 5],\n",
            "         [6, 7]]])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([ [[0, 1], [2, 3]], [[4, 5], [6, 7]]] )\n",
        "print(a)\n",
        "print(torch.flatten(a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GdQ1g2nilg_"
      },
      "source": [
        "### Transposing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VWIjOzilg_"
      },
      "source": [
        "It is possible to transpose a tensor (with a dimension at least 2) by specified dimesions using the\n",
        "function: \\`torch.transpose()\\`,\n",
        "This function takes the dimensions which are to be transposed as an argument.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6POptW5BilhA",
        "outputId": "556b9fb1-c505-48b8-f193-250d1f238c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[10, 20, 30],\n",
            "         [40, 50, 60],\n",
            "         [70, 80, 90]],\n",
            "\n",
            "        [[ 1,  2,  3],\n",
            "         [ 4,  5,  6],\n",
            "         [ 7,  8,  9]]])\n",
            "tensor([[[10, 40, 70],\n",
            "         [20, 50, 80],\n",
            "         [30, 60, 90]],\n",
            "\n",
            "        [[ 1,  4,  7],\n",
            "         [ 2,  5,  8],\n",
            "         [ 3,  6,  9]]])\n"
          ]
        }
      ],
      "source": [
        "tensor_1 = torch.tensor([[[10, 20, 30], [40, 50, 60], [70, 80, 90]],\n",
        "                         [[1,2,3],[4,5,6],[7,8,9]] ])\n",
        "tensor_1_transpose = torch.transpose(tensor_1, 1, 2)\n",
        "print(tensor_1)\n",
        "print(tensor_1_transpose)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TPSAILWilhA"
      },
      "source": [
        "### Tensor arithmetic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duz5zqeHilhB"
      },
      "source": [
        "The usual infix notation for arithmetic functions works element-wise on tensors:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JsBAL51BilhB",
        "outputId": "be45b00b-d7dd-47b4-925e-4a9b16f3b960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  6, 11])\n",
            "tensor([ 0, -2, -5])\n",
            "tensor([ 1,  8, 24])\n",
            "tensor([1.0000, 0.5000, 0.3750])\n",
            "tensor([  1,  16, 512])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "y = torch.tensor([1,4,8])\n",
        "print(x + y)\n",
        "print(x - y)\n",
        "print(x * y)\n",
        "print(x / y)\n",
        "print(y ** x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qXrFmZOilhC"
      },
      "source": [
        "### Broadcasting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L9Q7UQ_ilhC"
      },
      "source": [
        "When we apply these operations to tensors of different sizes, PyTorch will try to broadcast the input.\n",
        "\n",
        "For example, if we multiply a vector with a scalar, the scalar is broadcasted (extended) to a vector of the same length.\n",
        "The result is that each element in the vector is multiplied by that scalar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuLpu-BkilhC",
        "outputId": "5471f6a6-8c90-4de5-8654-57300fdc262f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "tensor([ 4,  8, 12])"
        }
      ],
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "print(x * 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0qpklbXilhD"
      },
      "source": [
        "Similarly, for higher dimensions.\n",
        "With the usual arithmetic operations, a row vector will be recycled in the obvious way.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO8VPVvRilhD",
        "outputId": "a16b6a5d-2c36-4358-b113-b5d4da5d64d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "multiplication:\n tensor([[ 1, 20],\n        [ 3, 40]])"
        }
      ],
      "source": [
        "row_vector = torch.tensor([1,10])\n",
        "matrix     = torch.tensor([[1,2], [3,4]])\n",
        "print(\"multiplication:\\n\", matrix * row_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8lwauVHilhD",
        "outputId": "a0d08231-0177-4a7a-a1ca-21aec5e0dd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "division:\n tensor([[1.0000, 0.2000],\n        [3.0000, 0.4000]])"
        }
      ],
      "source": [
        "print(\"division:\\n\" , matrix / row_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjFS4NOnilhE",
        "outputId": "c522df4e-9d83-4dfd-b491-9892e68391c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "addition:\n tensor([[ 2, 12],\n        [ 4, 14]])\nsubtraction:\n tensor([[ 0, -8],\n        [ 2, -6]])"
        }
      ],
      "source": [
        "print(\"addition:\\n\"    , matrix + row_vector)\n",
        "print(\"subtraction:\\n\" , matrix - row_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4BPhd9pilhE"
      },
      "source": [
        "The precise documentation of broadcasting is [here](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9INyZAvilhE"
      },
      "source": [
        "### Matrix Multiplication\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFXKqVopilhF"
      },
      "source": [
        "To perform a matrix multiplications on tensors, we use the function\n",
        "\\`torch.matmmul(tensor1, tensor2)\\`, or its short-form notation \\`tensor1 @ tensor2\\`.\n",
        "If \\`tensor1\\` is an $(n×m)$ tensor, and \\`tensor2\\` is an $(m×p)$ tensor, the\n",
        "output will be an $(n×p)$ tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJTiujESilhF",
        "outputId": "7944c522-56a0-4649-bf07-4a5101674f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "tensor([[ 12, 200],\n        [ 34, 400],\n        [ 56, 600]])\ntensor([[ 12, 200],\n        [ 34, 400],\n        [ 56, 600]])"
        }
      ],
      "source": [
        "tensor1 = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "tensor2 = torch.tensor([[10, 0], [1, 100]])\n",
        "print(torch.matmul(tensor1, tensor2))\n",
        "print(tensor1 @ tensor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu5tKO8cilhG"
      },
      "source": [
        "Notice that the function \\`torch.matmul()\\` implicitly converts and broadcasts and so also flexibly applies yields a matrix-vector product or a dot products.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c661Xa94ilhG",
        "outputId": "23d50d48-7c91-4521-9f94-1462e6086176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "tensor([[1, 2],\n        [3, 4],\n        [5, 6]])\ntensor([ 1, 10])\ntensor([21, 43, 65])\ntensor(101)"
        }
      ],
      "source": [
        "matrix = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "vector = torch.tensor([1,10])\n",
        "print(matrix)\n",
        "print(vector)\n",
        "print(matrix @ vector)  # matrix-vector product\n",
        "print(vector @ vector)  # dot prodcut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9vgQ8rWilhH"
      },
      "source": [
        "Full documentation of \\`torch.matmul()\\` is [here](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4rdrE8LilhH"
      },
      "source": [
        "### Assessing just the values of a tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z27cQpw2ilhH"
      },
      "source": [
        "The \\`tensor.item()\\` function returns the value of a single-item tensor without any further information, which is often useful for inspection or plotting of results:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD4kK9dqilhI",
        "outputId": "d2060ae0-1974-4060-8478-98b7b0973ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "tensor(4)\n4"
        }
      ],
      "source": [
        "tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "print(tensor[1,1])\n",
        "print(tensor[1,1].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ApSyuvVilhI"
      },
      "source": [
        "To convert a larger tensor back to numpy (e.g., for plotting) you can do this:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLZgoEsGilhI",
        "outputId": "72d66d7a-190b-4464-9eb1-40cb8dbc2d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "array([[1, 2, 3],\n       [4, 5, 6]])"
        }
      ],
      "source": [
        "another_tensor = torch.tensor([[1,2,3], [4,5,6]])\n",
        "another_tensor.detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSPvrq4iilhJ"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.4: Operations on tensors</span></strong>\n",
        ">\n",
        "> 1. Define a tensor for matrix $[[[1,2], [3,4], [5,6]]]$. Create new tensors obtained by Reshaping this matrix into a vector (row vector), a one-column matrix. Also, create its transpose.\n",
        ">\n",
        "> 2. Compute the dot product between $[1,3,5]$ and $[1,10,100]$.\n",
        ">\n",
        "> 3. Compute the matrix product between PyTorch tensors $[[1], [2], [3]]$ and $[[1,10,100]]$. Convert the result to a numpy array.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "org": null,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}