{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTfkvVHXkaRI"
      },
      "source": [
        "Sheet 1.1: Vanilla RSA\n",
        "======================\n",
        "\n",
        "**Author:** Michael Franke\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFz-6hbikaRU"
      },
      "source": [
        "This is a (numpy-based) Python implementation of a vanilla Rational Speech Act model for a reference game.\n",
        "\n",
        "The same model is also covered in [chapter 1 of problang.org](http://www.problang.org/chapters/01-introduction.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNyXmUe_kaRW"
      },
      "source": [
        "## Packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXAbcjJkaRY"
      },
      "source": [
        "The \\`numpy\\` package is used here in order to implement the RSA model using vector and matrix computation.\n",
        "Additionally, we use the \\`seaborn\\` package for visualizing the model&rsquo;s predictions.\n",
        "The input for the \\`seaborn\\` plots are Data Frames from the \\`pandas\\` package.\n",
        "We also might need \\`matplotlib\\` to produce (render) the plots.\n",
        "Finally, this notebook uses the \\`warnings\\` package to suppress all warning messages (not necessarily best practice in general, but acceptable here, as not all warnings are critical and could just distract).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pr5d183PkaRZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJsjLqQJkaRe"
      },
      "source": [
        "## Running example\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIqIwP2ikaRg"
      },
      "source": [
        "We will use a single running example here.\n",
        "The reference game in question is show below.\n",
        "\n",
        "![img](https://github.com/michael-franke/npNLG/blob/main/neural_pragmatic_nlg/pics/02-reference-game.png?raw=1)\n",
        "\n",
        "There are three objects, all of which could be the speaker&rsquo;s intended referent.\n",
        "The set of utterances consists of the expressions: &rsquo;blue&rsquo;, &rsquo;green&rsquo;, &rsquo;circle&rsquo; and &rsquo;square&rsquo;.\n",
        "\n",
        "In python code, we can represent this context as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Qyuyq0ekaRj"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "## defining the context\n",
        "##################################################\n",
        "\n",
        "object_names    = ['blue_circle', 'green_square', 'blue_square']\n",
        "utterance_names = ['blue', 'circle', 'green', 'square']\n",
        "\n",
        "semantic_meaning = np.array(\n",
        "    # blue circle, green square, blue square\n",
        "    [[1, 0, 1],  # blue\n",
        "     [1, 0, 0],  # circle\n",
        "     [0, 1, 0],  # green\n",
        "     [0, 1, 1]]  # square,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwPr-RFJkaRm"
      },
      "source": [
        "## Helper functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0HNDcankaRo"
      },
      "source": [
        "Two helper functions will come in handy:\n",
        "one for normalizing vectors and matrices;\n",
        "another for computing soft-max.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9C222p9xkaRp"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "## helper functions\n",
        "##################################################\n",
        "\n",
        "def softmax(x, axis=1):\n",
        "    \"\"\"\n",
        "    Softmax function in numpy\n",
        "    Parameters\n",
        "    ----------\n",
        "    x: array\n",
        "        An array with any dimensionality\n",
        "    axis: int\n",
        "        The axis along which to apply the softmax\n",
        "    Returns\n",
        "    -------\n",
        "    array\n",
        "        Same shape as x\n",
        "    \"\"\"\n",
        "    e_x = np.exp(x - np.max(x, axis, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "def normalize(arr, axis=1):\n",
        "    \"\"\"\n",
        "    Normalize arr along axis\n",
        "    \"\"\"\n",
        "    return arr / arr.sum(axis, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8mRsPrukaRr",
        "outputId": "b77e71e6-465e-4d8a-e2b6-88e4feec1aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.26894142 0.73105858]\n",
            " [0.26894142 0.73105858]\n",
            " [0.26894142 0.73105858]]\n",
            "[[0.01587624 0.01587624]\n",
            " [0.11731043 0.11731043]\n",
            " [0.86681333 0.86681333]]\n",
            "[0.09003057 0.24472847 0.66524096]\n",
            "[0.16666667 0.33333333 0.5       ]\n"
          ]
        }
      ],
      "source": [
        "##################################################\n",
        "## add solutions here for exercise 1.1.1\n",
        "##################################################\n",
        "#1.\n",
        "row_stochastic_matrix = normalize(np.array([[1,2], [3,4]]), axis=1)\n",
        "column_stochastic_matrix = normalize(np.array([[1,2], [3,4]]), axis=0)\n",
        "#2.\n",
        "row_stochastic = softmax(np.array([[1,2],[3,4],[5,6]]), axis=1)\n",
        "print(row_stochastic)\n",
        "column_stochastic = softmax(np.array([[1,2],[3,4],[5,6]]), axis=0)\n",
        "print(column_stochastic)\n",
        "#3.\n",
        "print(softmax(np.array([1, 2, 3]), axis=0))\n",
        "print(normalize(np.array([1, 2, 3]), axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4-iCF7skaRt"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 1.1.1: Apply the helper functions</span></strong>\n",
        "> 1. Normalize the following matrix to a row-stochastic and a column-stochastic matrix for the matrix: $[[1,2], [3,4]]$.\n",
        "> 2. Apply softmax to the following matrix to obtain a row-stochastic and a column-stochastic matrix:  $[[1,2], [3,4], [5,6]]$.\n",
        "> 3. Compute the soft-max and the normalized stochastic vector for the vector $[1,2,3]$. (NB: the definitions do *not* expect vector input, so &#x2026; what do you do?)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWidgbwzkaRv"
      },
      "source": [
        "## The model and its parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgyZE8VSkaRw"
      },
      "source": [
        "The model we want to implement is defined as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "P_{lit}(s \\mid u) & \\propto L(u,s) \\\\\n",
        "P_S( u \\mid s) &= \\mathrm{SoftMax}  \\left ( \\alpha \\left ( \\log P_{lit}(s \\mid u)  - \\mathrm{C}(u) \\right ) \\right ) \\\\\n",
        "P_L( s \\mid u) & \\propto P_{sal}(s) \\ P_S( u \\mid s)\n",
        "\\end{align*}\n",
        "\n",
        "Here, $L$ is a *lexicon*, which assigns a truth-value (usually 0 or 1) to each pair of utterance and state.\n",
        "The sign $\\propto$ is to be read as &ldquo;proportional to&rdquo; and implies proper normalization of the to-be-defined (conditional) distributions.\n",
        "The parameter $\\alpha$ is the usual &ldquo;optimality&rdquo; or &ldquo;inverse temperature&rdquo; parameter of the soft-max function.\n",
        "The cost function $C$ assigns a real number to each utterance, representing the relative effort or dispreference for that utterance.\n",
        "(NB: Since soft-max is only sensitive to (additive) differences, only differences in cost between utterances matter.)\n",
        "The salience prior $P_{sal}$ provides a relative weight of accessibility, salience or *a priori* bias for each object.\n",
        "\n",
        "The model&rsquo;s free parameters are: the optimality parameter $\\alpha$, the relative cost $C(u_{\\text{ajd}})$ of using an adjective (rather than a noun, where $C(u_{\\text{noun}})=0$), and the salience prior $P_{sal}$.\n",
        "\n",
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 1.1.2: Paraphrase the definitions</span></strong>\n",
        ">\n",
        "> Provide a short, intuitive and explanatory paraphrase for each of the three conditional probability distributions that define the RSA model above. I.e., formulate a sentence or two for each, so that a person can understand the purpose or gist of the definition. The less technical jargon you use, the better. The more insightful to a novice, the better.\n",
        "\n",
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Solutions for Exercise 1.1.2</span></strong>\n",
        ">\n",
        "> &#x2026; add your solution here &#x2026;\n",
        "\n",
        "1. The interpretation of a literal lisener is represented by a conditional probability of each state given the utterance, which is propotional to the truth values assigned to each pair of utterance and state.\n",
        "2. The probabilities of utterance choices of a pragmatic speaker are calculated by a soft-max function of the information content of a literal interpretation with given utterance deducted by its relative cost. \n",
        "3. The interpretation of the pragmatic lisener is propotional to their prior beliefs and the probabilities of utterance choices of a progmatic speaker in various\n",
        "states.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SldSTOhEkaRy"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "## model parameters\n",
        "##################################################\n",
        "\n",
        "alpha              = 1\n",
        "cost_adjectives    = 0.1\n",
        "salience_prior_flt = np.array([1,1,1])     # flat\n",
        "salience_prior_emp = np.array([71,139,30]) # empirical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF25HTArkaR0"
      },
      "source": [
        "## Implementation and visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qFkBvM2okaR1",
        "outputId": "5dbf2592-9096-4898-967e-8e02631401d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              blue  circle  green  square        object\n",
            "blue_circle   0.31    0.69   0.00    0.00   blue_circle\n",
            "green_square  0.00    0.00   0.64    0.36  green_square\n",
            "blue_square   0.48    0.00   0.00    0.52   blue_square\n",
            "        blue_circle  green_square  blue_square utterance\n",
            "blue            0.4           0.0          0.6      blue\n",
            "circle          1.0           0.0          0.0    circle\n",
            "green           0.0           1.0          0.0     green\n",
            "square          0.0           0.4          0.6    square\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x216 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x216 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "##################################################\n",
        "## RSA model predictions\n",
        "##################################################\n",
        "\n",
        "\n",
        "def RSA(alpha, cost_adjectives, salience_prior):\n",
        "    \"\"\"\n",
        "    predictions of the vanilla RSA model for reference game\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha: float\n",
        "        Optimality parameter\n",
        "    cost_adjectives: float\n",
        "        Differential cost for production of adjectives\n",
        "    salience_prior: array\n",
        "        Prior over objects\n",
        "    Returns\n",
        "    -------\n",
        "    dictionary\n",
        "        Dictionary with keys 'speaker' and 'listener'\n",
        "    \"\"\"\n",
        "    costs              = np.array([1.0, 0, 1.0, 0]) * cost_adjectives\n",
        "    literal_listener   = normalize(semantic_meaning)\n",
        "    util_speaker       = np.log(np.transpose(literal_listener)) - costs\n",
        "    pragmatic_speaker  = softmax(alpha * util_speaker)\n",
        "    pragmatic_listener = normalize(np.transpose(pragmatic_speaker) * salience_prior)\n",
        "    return({'speaker': pragmatic_speaker, 'listener': pragmatic_listener})\n",
        "\n",
        "RSA_predictions = RSA(alpha, cost_adjectives, salience_prior_flt)\n",
        "\n",
        "##################################################\n",
        "## cast model predictions to DataFrames\n",
        "##################################################\n",
        "\n",
        "speaker  = pd.DataFrame(data = RSA_predictions['speaker'],\n",
        "                        index = object_names,\n",
        "                        columns = utterance_names)\n",
        "speaker['object'] = speaker.index\n",
        "print(speaker.round(2))\n",
        "\n",
        "listener = pd.DataFrame(data    = RSA_predictions['listener'],\n",
        "                        index   = utterance_names,\n",
        "                        columns = object_names)\n",
        "listener['utterance'] = listener.index\n",
        "print(listener.round(2))\n",
        "\n",
        "##################################################\n",
        "## plotting the results\n",
        "##################################################\n",
        "\n",
        "speaker_long = speaker.melt(id_vars = \"object\", var_name = \"utterance\",\n",
        "                            value_name = \"probability\", ignore_index = False)\n",
        "speaker_plot = sns.FacetGrid(speaker_long, col=\"object\")\n",
        "speaker_plot.map(sns.barplot, \"utterance\", \"probability\")\n",
        "plt.show()\n",
        "\n",
        "listener_long = listener.melt(id_vars = \"utterance\", var_name = \"object\",\n",
        "                              value_name = \"probability\", ignore_index = False)\n",
        "listener_plot = sns.FacetGrid(listener_long, col=\"utterance\")\n",
        "listener_plot.map(sns.barplot, \"object\", \"probability\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMhzlNw4kaR6"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 1.1.3: Explore the vanilla RSA model</span></strong>\n",
        ">\n",
        "> 0. [for your own sake only; no written answer required] Go through the whole last code block. Try to understand every single line in the function \\`RSA<sub>predictions</sub>\\`. Ask if anything is unclear. (It is muss less important to understand the details of the subsequent data wrangling and plotting.)\n",
        "> 1. Explore what happens if you make the speaker more optimal. Does that also affect the listener&rsquo;s inferences? Why? Is that intuitive?\n",
        "> 2. Add another object to the context, namely a red triangle. Add any relevant utterances, their semantics and costs as well. What do you predict will happen to the model&rsquo;s predictions for the &ldquo;old&rdquo; objects and utterances? Test your predictions (= understanding of the model) and report the results.\n",
        "> 3. Run the model with different values for the cost parameter \\`cost<sub>adjectives</sub>\\`. Which effect does this have on the speaker prediction? Which effect does that have on the predictions for listener interpretation? Explain these observation in your own non-technical terms (e.g., for an interested outsider).\n",
        "> 4. Is there any way to get “blue” to refer to something green? I.e., is it possible (if so: how?; else: why not?) to change the context or model in such a way that $P_{L}(\\text{green square} \\mid \\text{blue}) > 0$, ideally in a way that might also be defensible in that it makes conceptual sense (not just by some technical trick that no reviewer of your work would accept as anything but a hack)?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1.1.3.1\n",
        "\n",
        "# to make the speaker more optimal, I increase the alpha value to 2\n",
        "alpha = 2\n",
        "\n",
        "# run model and print out predictions\n",
        "RSA_predictions = RSA(alpha, cost_adjectives, salience_prior_flt)\n",
        "speaker  = pd.DataFrame(data = RSA_predictions['speaker'],\n",
        "                        index = object_names,\n",
        "                        columns = utterance_names)\n",
        "speaker['object'] = speaker.index\n",
        "print(speaker.round(2))\n",
        "\n",
        "listener = pd.DataFrame(data    = RSA_predictions['listener'],\n",
        "                        index   = utterance_names,\n",
        "                        columns = object_names)\n",
        "listener['utterance'] = listener.index\n",
        "print(listener.round(2))"
      ],
      "metadata": {
        "id": "vvW0WJXMlU0B",
        "outputId": "8d85e522-d334-4a94-e9fa-25996ecaa6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              blue  circle  green  square        object\n",
            "blue_circle   0.17    0.83   0.00    0.00   blue_circle\n",
            "green_square  0.00    0.00   0.77    0.23  green_square\n",
            "blue_square   0.45    0.00   0.00    0.55   blue_square\n",
            "        blue_circle  green_square  blue_square utterance\n",
            "blue           0.27           0.0         0.73      blue\n",
            "circle         1.00           0.0         0.00    circle\n",
            "green          0.00           1.0         0.00     green\n",
            "square         0.00           0.3         0.70    square\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the printed result, after making the speaker more optimal, the listener's inference also becomes more optimal. That is intuitive, because if the lisener presuppose a more rational speaker, they should also make more rational inferences. Besides, since in this model the inferences of listeners are calculated based on the utterance choices of pragmatic speaker, the change in utterance probablities should also influence inferences."
      ],
      "metadata": {
        "id": "Rq41F8l4tsWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1.1.3.2\n",
        "\n",
        "# my prediction: adding of a red triangle would not influence the model's \n",
        "# predictions on the old objects, since red triangle has no common property\n",
        "# with previous objects, and therefore would not change the conditional \n",
        "# probabilities of the utterances of the old properties given the old objects\n",
        "\n",
        "# add a red triangle to the context\n",
        "object_names    = ['blue_circle', 'green_square', 'blue_square', 'red_triangle']\n",
        "utterance_names = ['blue', 'circle', 'green', 'square', 'red', 'triangle']\n",
        "semantic_meaning = np.array(\n",
        "    # blue circle, green square, blue square, red triangle\n",
        "    [[1, 0, 1, 0],  # blue\n",
        "     [1, 0, 0, 0],  # circle\n",
        "     [0, 1, 0, 0],  # green\n",
        "     [0, 1, 1, 0],  # square\n",
        "     [0, 0, 0, 1],  # red\n",
        "     [0, 0, 0, 1]   # trianle\n",
        "    ])\n",
        "\n",
        "# modify model parameters\n",
        "alpha              = 1\n",
        "cost_adjectives    = 0.1\n",
        "salience_prior_flt = np.array([1,1,1,1])     # flat\n",
        "\n",
        "# modify model definition\n",
        "def RSA(alpha, cost_adjectives, salience_prior):\n",
        "    \"\"\"\n",
        "    predictions of the vanilla RSA model for reference game\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha: float\n",
        "        Optimality parameter\n",
        "    cost_adjectives: float\n",
        "        Differential cost for production of adjectives\n",
        "    salience_prior: array\n",
        "        Prior over objects\n",
        "    Returns\n",
        "    -------\n",
        "    dictionary\n",
        "        Dictionary with keys 'speaker' and 'listener'\n",
        "    \"\"\"\n",
        "    costs              = np.array([1.0, 0, 1.0, 0, 1.0, 0]) * cost_adjectives\n",
        "    literal_listener   = normalize(semantic_meaning)\n",
        "    util_speaker       = np.log(np.transpose(literal_listener)) - costs\n",
        "    pragmatic_speaker  = softmax(alpha * util_speaker)\n",
        "    pragmatic_listener = normalize(np.transpose(pragmatic_speaker) * salience_prior)\n",
        "    return({'speaker': pragmatic_speaker, 'listener': pragmatic_listener})\n",
        "\n",
        "# run model and print out predictions\n",
        "RSA_predictions = RSA(alpha, cost_adjectives, salience_prior_flt)\n",
        "speaker  = pd.DataFrame(data = RSA_predictions['speaker'],\n",
        "                        index = object_names,\n",
        "                        columns = utterance_names)\n",
        "speaker['object'] = speaker.index\n",
        "print(speaker.round(2))\n",
        "\n",
        "listener = pd.DataFrame(data    = RSA_predictions['listener'],\n",
        "                        index   = utterance_names,\n",
        "                        columns = object_names)\n",
        "listener['utterance'] = listener.index\n",
        "print(listener.round(2))"
      ],
      "metadata": {
        "id": "lyEWP28svFcP",
        "outputId": "121e7c78-a28a-4f2a-f199-20c6f91034da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              blue  circle  green  square   red  triangle        object\n",
            "blue_circle   0.31    0.69   0.00    0.00  0.00      0.00   blue_circle\n",
            "green_square  0.00    0.00   0.64    0.36  0.00      0.00  green_square\n",
            "blue_square   0.48    0.00   0.00    0.52  0.00      0.00   blue_square\n",
            "red_triangle  0.00    0.00   0.00    0.00  0.48      0.52  red_triangle\n",
            "          blue_circle  green_square  blue_square  red_triangle utterance\n",
            "blue              0.4           0.0          0.6           0.0      blue\n",
            "circle            1.0           0.0          0.0           0.0    circle\n",
            "green             0.0           1.0          0.0           0.0     green\n",
            "square            0.0           0.4          0.6           0.0    square\n",
            "red               0.0           0.0          0.0           1.0       red\n",
            "triangle          0.0           0.0          0.0           1.0  triangle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the printed results, the adding of a red triangle indeed did not interfere with the predictions of old objects."
      ],
      "metadata": {
        "id": "QKxuZUEb3gLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1.1.3.3\n",
        "\n",
        "# experiment by incrementing the cost of adjectives to 1\n",
        "cost_adjectives    = 0.1\n",
        "\n",
        "# run model and print out predictions\n",
        "RSA_predictions = RSA(alpha, cost_adjectives, salience_prior_flt)\n",
        "speaker  = pd.DataFrame(data = RSA_predictions['speaker'],\n",
        "                        index = object_names,\n",
        "                        columns = utterance_names)\n",
        "speaker['object'] = speaker.index\n",
        "print(speaker.round(2))\n",
        "\n",
        "listener = pd.DataFrame(data    = RSA_predictions['listener'],\n",
        "                        index   = utterance_names,\n",
        "                        columns = object_names)\n",
        "listener['utterance'] = listener.index\n",
        "print(listener.round(2))"
      ],
      "metadata": {
        "id": "RhkTtx5V31ZG",
        "outputId": "e348e3cc-cd0f-4a7c-8d39-a89169234b1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              blue  circle  green  square   red  triangle        object\n",
            "blue_circle   0.31    0.69   0.00    0.00  0.00      0.00   blue_circle\n",
            "green_square  0.00    0.00   0.64    0.36  0.00      0.00  green_square\n",
            "blue_square   0.48    0.00   0.00    0.52  0.00      0.00   blue_square\n",
            "red_triangle  0.00    0.00   0.00    0.00  0.48      0.52  red_triangle\n",
            "          blue_circle  green_square  blue_square  red_triangle utterance\n",
            "blue              0.4           0.0          0.6           0.0      blue\n",
            "circle            1.0           0.0          0.0           0.0    circle\n",
            "green             0.0           1.0          0.0           0.0     green\n",
            "square            0.0           0.4          0.6           0.0    square\n",
            "red               0.0           0.0          0.0           1.0       red\n",
            "triangle          0.0           0.0          0.0           1.0  triangle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxlXAFSIkaR9"
      },
      "source": [
        "## References\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FcxGrztkaR_"
      },
      "source": [
        "Frank, M. C., & Goodman, N. D. (2012). Predicting pragmatic reasoning in language games. Science, 336(6084), 998. [http://dx.doi.org/10.1126/science.1218633](http://dx.doi.org/10.1126/science.1218633)\n",
        "\n",
        "Scontras, G., Tessler, M. H., & Franke, M. (2018). [Probabilistic language understanding: An introduction to the Rational Speech Act framework](http://www.problang.org/).\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "org": null,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}